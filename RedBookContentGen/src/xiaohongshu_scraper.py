#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å°çº¢ä¹¦å†…å®¹æœç´¢å™¨
ä½¿ç”¨æµè§ˆå™¨è‡ªåŠ¨åŒ–æœç´¢å°çº¢ä¹¦,æå–é«˜åˆ†ç¬”è®°å†…å®¹
"""

import os
import json
import time
from typing import List, Dict, Optional
import re


class XiaohongshuScraper:
    """å°çº¢ä¹¦å†…å®¹æœç´¢å™¨"""

    def __init__(self, config_path: str = "config/config.json"):
        """
        åˆå§‹åŒ–æœç´¢å™¨

        Args:
            config_path: é…ç½®æ–‡ä»¶è·¯å¾„
        """
        self.config = self._load_config(config_path)
        self.xhs_config = self.config.get("xiaohongshu", {})
        self.driver = None

    def _load_config(self, config_path: str) -> dict:
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        default_xhs_config = {
            "search_mode": "browser",
            "browser_type": "chrome",
            "headless": False,  # å°çº¢ä¹¦åœ¨æ— å¤´æ¨¡å¼ä¸‹å¯èƒ½ä¸åŠ è½½å†…å®¹
            "max_search_results": 10,
            "min_likes_threshold": 1000,
            "login_required": False,
            "request_delay": 2,  # è¯·æ±‚é—´éš”(ç§’)
        }

        if os.path.exists(config_path):
            with open(config_path, "r", encoding="utf - 8") as f:
                config = json.load(f)
                if "xiaohongshu" not in config:
                    config["xiaohongshu"] = default_xhs_config
                else:
                    # åˆå¹¶é»˜è®¤é…ç½®
                    for key, value in default_xhs_config.items():
                        if key not in config["xiaohongshu"]:
                            config["xiaohongshu"][key] = value
                return config
        else:
            return {"xiaohongshu": default_xhs_config}

    def _init_browser(self):
        """åˆå§‹åŒ–æµè§ˆå™¨é©±åŠ¨"""
        if self.driver:
            return

        try:
            from selenium import webdriver
            from selenium.webdriver.chrome.service import Service
            from selenium.webdriver.chrome.options import Options

            chrome_options = Options()

            # è®¾ç½®æ— å¤´æ¨¡å¼
            if self.xhs_config.get("headless", True):
                chrome_options.add_argument("--headless=new")  # ä½¿ç”¨æ–°çš„headlessæ¨¡å¼
                chrome_options.add_argument("--no-sandbox")
                chrome_options.add_argument("--disable-dev-shm-usage")

            # åçˆ¬è™«è®¾ç½®
            chrome_options.add_argument("--disable-blink-features=AutomationControlled")
            chrome_options.add_experimental_option("excludeSwitches", ["enable-automation"])
            chrome_options.add_experimental_option("useAutomationExtension", False)

            # è®¾ç½®User-Agent
            chrome_options.add_argument(
                "user-agent=Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) "
                "AppleWebKit/537.36 (KHTML, like Gecko) "
                "Chrome/120.0.0.0 Safari/537.36"
            )

            # åˆå§‹åŒ–é©±åŠ¨ - ä¼˜å…ˆä½¿ç”¨ç³»ç»Ÿchromedriver
            try:
                # å°è¯•ç›´æ¥ä½¿ç”¨ç³»ç»Ÿçš„chromedriver
                self.driver = webdriver.Chrome(options=chrome_options)
                print("âœ… æµè§ˆå™¨é©±åŠ¨åˆå§‹åŒ–æˆåŠŸ (ç³»ç»Ÿé©±åŠ¨)")
            except Exception:
                # å¦‚æœç³»ç»Ÿæ²¡æœ‰chromedriver,å°è¯•ç”¨webdriver-managerä¸‹è½½
                try:
                    from webdriver_manager.chrome import ChromeDriverManager

                    service = Service(ChromeDriverManager().install())
                    self.driver = webdriver.Chrome(service=service, options=chrome_options)
                    print("âœ… æµè§ˆå™¨é©±åŠ¨åˆå§‹åŒ–æˆåŠŸ (è‡ªåŠ¨ä¸‹è½½)")
                except Exception as e:
                    raise RuntimeError(
                        f"æ— æ³•åˆå§‹åŒ–Chromeé©±åŠ¨ã€‚è¯·ç¡®ä¿: 1)å·²å®‰è£…Chromeæµè§ˆå™¨ 2)ç½‘ç»œè¿æ¥æ­£å¸¸ 3)æˆ–æ‰‹åŠ¨å®‰è£…chromedriverã€‚é”™è¯¯: {e}"
                    )

            # è®¾ç½®éšå¼ç­‰å¾…
            self.driver.implicitly_wait(10)

        except Exception as e:
            raise RuntimeError(f"âŒ æµè§ˆå™¨é©±åŠ¨åˆå§‹åŒ–å¤±è´¥: {e}")

    def search_by_topic(self, topic: str, max_results: Optional[int] = None) -> List[Dict]:
        """
        æ ¹æ®ä¸»é¢˜æœç´¢å°çº¢ä¹¦ç¬”è®°

        Args:
            topic: æœç´¢ä¸»é¢˜å…³é”®è¯
            max_results: æœ€å¤§ç»“æœæ•°(Noneåˆ™ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„å€¼)

        Returns:
            ç¬”è®°åˆ—è¡¨,æ¯ä¸ªç¬”è®°åŒ…å« title, author, likes, url, preview_text ç­‰ä¿¡æ¯
        """
        if max_results is None:
            max_results = self.xhs_config.get("max_search_results", 10)

        print(f"\nğŸ” å¼€å§‹æœç´¢ä¸»é¢˜: {topic}")
        print(f"   ç›®æ ‡è·å–: {max_results} æ¡ç¬”è®°")

        try:
            pass

            # åˆå§‹åŒ–æµè§ˆå™¨
            self._init_browser()

            # æ„å»ºæœç´¢URL
            search_url = f"https://www.xiaohongshu.com/search_result?keyword={topic}&source=web_search_result_notes"
            self.driver.get(search_url)

            # ç­‰å¾…é¡µé¢åŠ è½½
            time.sleep(3)

            # æ»‘åŠ¨é¡µé¢ä»¥åŠ è½½æ›´å¤šå†…å®¹
            self._scroll_page(scroll_times=3)

            # æå–ç¬”è®°å¡ç‰‡
            notes = self._extract_note_cards(max_results)

            print(f"âœ… æˆåŠŸè·å– {len(notes)} æ¡ç¬”è®°")
            return notes

        except Exception as e:
            print(f"âŒ æœç´¢å¤±è´¥: {e}")
            raise

    def _scroll_page(self, scroll_times: int = 3):
        """
        æ»‘åŠ¨é¡µé¢ä»¥åŠ è½½æ›´å¤šå†…å®¹

        Args:
            scroll_times: æ»‘åŠ¨æ¬¡æ•°
        """
        for i in range(scroll_times):
            self.driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
            time.sleep(self.xhs_config.get("request_delay", 2))
            print(f"   ğŸ“„ æ»‘åŠ¨é¡µé¢ ({i + 1}/{scroll_times})")

    def _extract_note_cards(self, max_results: int) -> List[Dict]:
        """
        æå–ç¬”è®°å¡ç‰‡ä¿¡æ¯

        Args:
            max_results: æœ€å¤§æå–æ•°é‡

        Returns:
            ç¬”è®°åˆ—è¡¨
        """
        from selenium.webdriver.common.by import By

        notes = []

        try:
            # å°çº¢ä¹¦çš„ç¬”è®°å¡ç‰‡é€‰æ‹©å™¨ - ä½¿ç”¨sectionå…ƒç´ 
            note_elements = self.driver.find_elements(By.CSS_SELECTOR, "section")

            print(f"   æ‰¾åˆ° {len(note_elements)} ä¸ªç¬”è®°å…ƒç´ ")

            for idx, element in enumerate(note_elements[: max_results * 2]):  # å¤šå–ä¸€äº›ä»¥åº”å¯¹è§£æå¤±è´¥
                try:
                    note_data = self._parse_note_element(element)
                    if note_data:
                        notes.append(note_data)
                        print(
                            f"   âœ“ [{len(notes)}] {note_data.get('title', 'æ— æ ‡é¢˜')[:30]}... (ğŸ‘ {note_data.get('likes', 0)})"
                        )

                        # è¾¾åˆ°ç›®æ ‡æ•°é‡å°±åœæ­¢
                        if len(notes) >= max_results:
                            break
                except Exception:
                    # é™é»˜è·³è¿‡è§£æå¤±è´¥çš„å…ƒç´ 
                    continue

        except Exception as e:
            print(f"   âš ï¸  æå–ç¬”è®°åˆ—è¡¨å¤±è´¥: {e}")

        return notes

    def _parse_note_element(self, element) -> Optional[Dict]:
        """
        è§£æå•ä¸ªç¬”è®°å…ƒç´ 

        Args:
            element: Selenium WebElement

        Returns:
            ç¬”è®°æ•°æ®å­—å…¸
        """
        from selenium.webdriver.common.by import By

        try:
            note_data = {}

            # æå–æ ‡é¢˜ - ä½¿ç”¨a.titleé€‰æ‹©å™¨
            try:
                title_elem = element.find_element(By.CSS_SELECTOR, "a.title")
                note_data["title"] = title_elem.text.strip()
            except Exception:
                # å¦‚æœæ²¡æœ‰title,å¯èƒ½ä¸æ˜¯æœ‰æ•ˆçš„ç¬”è®°å¡ç‰‡
                return None

            # æå–é“¾æ¥ - å¯ä»¥ä»a.coveræˆ–a.titleè·å–
            try:
                # ä¼˜å…ˆä½¿ç”¨titleé“¾æ¥
                link_elem = element.find_element(By.CSS_SELECTOR, "a.title, a.cover")
                link = link_elem.get_attribute("href")
                if link:
                    # å¦‚æœæ˜¯ç›¸å¯¹è·¯å¾„,è¡¥å…¨ä¸ºç»å¯¹è·¯å¾„
                    if link.startswith("/"):
                        link = f"https://www.xiaohongshu.com{link}"
                    note_data["url"] = link
                else:
                    return None
            except Exception:
                return None

            # æå–ç‚¹èµæ•° - ä½¿ç”¨span.counté€‰æ‹©å™¨
            try:
                likes_elem = element.find_element(By.CSS_SELECTOR, "span.count")
                likes_text = likes_elem.text.strip()
                note_data["likes"] = self._parse_number(likes_text)
            except Exception:
                note_data["likes"] = 0

            # æå–ä½œè€… - ä½¿ç”¨a.authoré€‰æ‹©å™¨
            try:
                author_elem = element.find_element(By.CSS_SELECTOR, "a.author")
                # authorå¯èƒ½åœ¨å­å…ƒç´ ä¸­
                author_text = author_elem.text.strip()
                if not author_text:
                    # å°è¯•ä»å­å…ƒç´ è·å–
                    author_div = author_elem.find_element(By.CSS_SELECTOR, "div, span")
                    author_text = author_div.text.strip()
                note_data["author"] = author_text if author_text else "æœªçŸ¥ä½œè€…"
            except Exception:
                note_data["author"] = "æœªçŸ¥ä½œè€…"

            # æå–é¢„è§ˆæ–‡æœ¬(å°è¯•ä»titleè·å–,å› ä¸ºæœç´¢é¡µé€šå¸¸æ²¡æœ‰å®Œæ•´æè¿°)
            note_data["preview_text"] = note_data["title"]

            return note_data if note_data.get("url") and note_data.get("title") else None

        except Exception:
            return None

    def _parse_number(self, text: str) -> int:
        """
        è§£ææ•°å­—æ–‡æœ¬(æ”¯æŒ1.2w, 3kç­‰æ ¼å¼)

        Args:
            text: æ•°å­—æ–‡æœ¬

        Returns:
            æ•´æ•°å€¼
        """
        if not text:
            return 0

        text = text.strip().lower()

        # ç§»é™¤éæ•°å­—å’Œå•ä½å­—ç¬¦
        multiplier = 1
        if "w" in text or "ä¸‡" in text:
            multiplier = 10000
            text = text.replace("w", "").replace("ä¸‡", "")
        elif "k" in text or "åƒ" in text:
            multiplier = 1000
            text = text.replace("k", "").replace("åƒ", "")

        # æå–æ•°å­—
        match = re.search(r"[\d.]+", text)
        if match:
            number = float(match.group())
            return int(number * multiplier)

        return 0

    def get_note_content(self, note_url: str) -> Optional[Dict]:
        """
        è·å–å•æ¡ç¬”è®°çš„è¯¦ç»†å†…å®¹

        Args:
            note_url: ç¬”è®°URL

        Returns:
            ç¬”è®°è¯¦ç»†å†…å®¹å­—å…¸
        """
        if not note_url:
            return None

        try:
            from selenium.webdriver.common.by import By

            # åˆå§‹åŒ–æµè§ˆå™¨
            self._init_browser()

            print(f"   ğŸ“– è·å–ç¬”è®°è¯¦æƒ…: {note_url[:50]}...")

            # è®¿é—®ç¬”è®°é¡µé¢
            self.driver.get(note_url)
            time.sleep(self.xhs_config.get("request_delay", 2))

            content_data = {}

            # æå–æ ‡é¢˜
            try:
                title_elem = self.driver.find_element(By.CSS_SELECTOR, "#detail-title, .title")
                content_data["title"] = title_elem.text.strip()
            except Exception:
                content_data["title"] = ""

            # æå–æ­£æ–‡
            try:
                content_elem = self.driver.find_element(By.CSS_SELECTOR, "#detail-desc, .desc, .content")
                content_data["content"] = content_elem.text.strip()
            except Exception:
                content_data["content"] = ""

            # æå–æ ‡ç­¾
            try:
                tag_elements = self.driver.find_elements(By.CSS_SELECTOR, ".tag, .topic")
                content_data["tags"] = [tag.text.strip() for tag in tag_elements]
            except Exception:
                content_data["tags"] = []

            # æå–äº’åŠ¨æ•°æ®
            try:
                likes_elem = self.driver.find_element(By.CSS_SELECTOR, ".like-count")
                content_data["likes"] = self._parse_number(likes_elem.text)
            except Exception:
                content_data["likes"] = 0

            try:
                collect_elem = self.driver.find_element(By.CSS_SELECTOR, ".collect-count")
                content_data["collects"] = self._parse_number(collect_elem.text)
            except Exception:
                content_data["collects"] = 0

            content_data["url"] = note_url

            print("   âœ… è·å–æˆåŠŸ")
            return content_data

        except Exception as e:
            print(f"   âŒ è·å–ç¬”è®°å†…å®¹å¤±è´¥: {e}")
            return None

    def filter_high_quality_notes(self, notes: List[Dict], min_likes: Optional[int] = None) -> List[Dict]:
        """
        ç­›é€‰é«˜è´¨é‡ç¬”è®°

        Args:
            notes: ç¬”è®°åˆ—è¡¨
            min_likes: æœ€å°ç‚¹èµæ•°(Noneåˆ™ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„å€¼)

        Returns:
            ç­›é€‰åçš„ç¬”è®°åˆ—è¡¨
        """
        if min_likes is None:
            min_likes = self.xhs_config.get("min_likes_threshold", 1000)

        print(f"\nğŸ¯ ç­›é€‰é«˜è´¨é‡ç¬”è®° (æœ€å°ç‚¹èµæ•°: {min_likes})")

        filtered = [note for note in notes if note.get("likes", 0) >= min_likes]

        # æŒ‰ç‚¹èµæ•°æ’åº
        filtered.sort(key=lambda x: x.get("likes", 0), reverse=True)

        print(f"âœ… ç­›é€‰å‡º {len(filtered)} æ¡é«˜è´¨é‡ç¬”è®°")

        return filtered

    def close(self):
        """å…³é—­æµè§ˆå™¨"""
        if self.driver:
            self.driver.quit()
            self.driver = None
            print("âœ… æµè§ˆå™¨å·²å…³é—­")

    def __enter__(self):
        """ä¸Šä¸‹æ–‡ç®¡ç†å™¨å…¥å£"""
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        """ä¸Šä¸‹æ–‡ç®¡ç†å™¨é€€å‡º"""
        self.close()


def main():
    """æµ‹è¯•å‡½æ•°"""
    import argparse

    parser = argparse.ArgumentParser(description="å°çº¢ä¹¦å†…å®¹æœç´¢å™¨")
    parser.add_argument("topic", help="æœç´¢ä¸»é¢˜")
    parser.add_argument("-n", "--max-results", type=int, default=10, help="æœ€å¤§ç»“æœæ•°")
    parser.add_argument("-m", "--min-likes", type=int, default=1000, help="æœ€å°ç‚¹èµæ•°")
    parser.add_argument("-c", "--config", default="config/config.json", help="é…ç½®æ–‡ä»¶è·¯å¾„")

    args = parser.parse_args()

    # ä½¿ç”¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨ç¡®ä¿æµè§ˆå™¨æ­£ç¡®å…³é—­
    with XiaohongshuScraper(config_path=args.config) as scraper:
        # æœç´¢ç¬”è®°
        notes = scraper.search_by_topic(args.topic, max_results=args.max_results)

        # ç­›é€‰é«˜è´¨é‡ç¬”è®°
        if notes:
            filtered_notes = scraper.filter_high_quality_notes(notes, min_likes=args.min_likes)

            # æ‰“å°ç»“æœ
            print(f"\n{'=' * 60}")
            print(f"æœç´¢ä¸»é¢˜: {args.topic}")
            print(f"æ‰¾åˆ°ç¬”è®°: {len(notes)} æ¡")
            print(f"é«˜è´¨é‡ç¬”è®°: {len(filtered_notes)} æ¡")
            print(f"{'=' * 60}\n")

            for idx, note in enumerate(filtered_notes, 1):
                print(f"[{idx}] {note.get('title', 'æ— æ ‡é¢˜')}")
                print(f"    ä½œè€…: {note.get('author', 'æœªçŸ¥')}")
                print(f"    ç‚¹èµ: {note.get('likes', 0)}")
                print(f"    é“¾æ¥: {note.get('url', '')}")
                if note.get("preview_text"):
                    print(f"    é¢„è§ˆ: {note.get('preview_text', '')[:100]}...")
                print()


if __name__ == "__main__":
    main()
