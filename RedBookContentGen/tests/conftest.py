#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
pytest é…ç½®æ–‡ä»¶

æä¾›å…¨å±€çš„æµ‹è¯•å›ºä»¶å’Œé…ç½®
"""

import os
import sys
import tempfile
from pathlib import Path
from typing import Dict, Any
import pytest

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))


# ============================================================================
# é…ç½®å›ºä»¶
# ============================================================================


@pytest.fixture
def temp_dir():
    """åˆ›å»ºä¸´æ—¶ç›®å½•"""
    with tempfile.TemporaryDirectory() as tmpdir:
        yield Path(tmpdir)


@pytest.fixture
def sample_config() -> Dict[str, Any]:
    """æä¾›ç¤ºä¾‹é…ç½®"""
    return {
        "api": {
            "openai": {
                "key": "test-api-key",
                "base_url": "https://dashscope.aliyuncs.com/compatible-mode/v1",
                "model": "qwen-plus",
                "timeout": 30,
                "max_retries": 3,
            },
            "image": {"model": "wan2.2-t2i-flash", "size": "1024*1365", "timeout": 180},
        },
        "cache": {"enabled": True, "ttl": 3600, "max_size": "1GB"},
        "rate_limit": {
            "openai": {"requests_per_minute": 60, "tokens_per_minute": 90000},
            "image": {"requests_per_minute": 10},
        },
        "logging": {
            "level": "INFO",
            "format": "json",
            "file": "logs/app.log",
            "max_bytes": 10485760,
            "backup_count": 5,
        },
    }


@pytest.fixture
def mock_config_file(temp_dir, sample_config):
    """åˆ›å»ºä¸´æ—¶é…ç½®æ–‡ä»¶"""
    import json

    config_file = temp_dir / "config.json"
    with open(config_file, "w", encoding="utf-8") as f:
        json.dump(sample_config, f, ensure_ascii=False, indent=2)
    return config_file


# ============================================================================
# ç¯å¢ƒå˜é‡å›ºä»¶
# ============================================================================


@pytest.fixture
def clean_env(monkeypatch):
    """æ¸…ç†ç¯å¢ƒå˜é‡"""
    env_vars = [
        "OPENAI_API_KEY",
        "OPENAI_MODEL",
        "OPENAI_BASE_URL",
        "RATE_LIMIT_OPENAI_RPM",
        "CACHE_ENABLED",
        "LOG_LEVEL",
    ]
    for var in env_vars:
        monkeypatch.delenv(var, raising=False)
    yield


@pytest.fixture
def mock_env(monkeypatch):
    """è®¾ç½®æ¨¡æ‹Ÿç¯å¢ƒå˜é‡"""
    monkeypatch.setenv("OPENAI_API_KEY", "test-key-from-env")
    monkeypatch.setenv("OPENAI_MODEL", "qwen-max")
    monkeypatch.setenv("LOG_LEVEL", "DEBUG")
    yield


# ============================================================================
# æµ‹è¯•æ•°æ®å›ºä»¶
# ============================================================================


@pytest.fixture
def sample_input_text() -> str:
    """æä¾›ç¤ºä¾‹è¾“å…¥æ–‡æœ¬"""
    return """
    è®°å¾—å°æ—¶å€™ï¼Œè€åŒ—äº¬çš„èƒ¡åŒé‡Œæ€»æ˜¯å……æ»¡äº†ç”Ÿæ´»çš„æ°”æ¯ã€‚
    æ¸…æ™¨ï¼Œå–è±†è…çš„å†å–å£°ä»å··å­æ·±å¤„ä¼ æ¥ï¼Œæ‚ é•¿è€Œäº²åˆ‡ã€‚
    é‚»é‡Œä¹‹é—´ä¸²é—¨èŠå¤©ï¼Œå­©å­ä»¬åœ¨èƒ¡åŒé‡Œè¿½é€å¬‰æˆã€‚
    é‚£æ—¶å€™çš„ç”Ÿæ´»è™½ç„¶ç®€å•ï¼Œä½†å……æ»¡äº†äººæƒ…å‘³ã€‚
    """


@pytest.fixture
def sample_content_result() -> Dict[str, Any]:
    """æä¾›ç¤ºä¾‹å†…å®¹ç”Ÿæˆç»“æœ"""
    return {
        "titles": ["èƒ¡åŒé‡Œçš„è€åŒ—äº¬è®°å¿† ğŸ®", "é‚£äº›å¹´ï¼Œæˆ‘ä»¬ä¸€èµ·èµ°è¿‡çš„èƒ¡åŒ", "è€åŒ—äº¬èƒ¡åŒï¼šæ—¶å…‰é‡Œçš„æ¸©æš–"],
        "content": "è®°å¾—å°æ—¶å€™çš„è€åŒ—äº¬èƒ¡åŒå—ï¼Ÿæ¸…æ™¨çš„è±†è…å†å–å£°...",
        "tags": ["#è€åŒ—äº¬", "#èƒ¡åŒæ–‡åŒ–", "#ç«¥å¹´å›å¿†", "#åŒ—äº¬ç”Ÿæ´»"],
        "image_prompts": [
            "è€åŒ—äº¬èƒ¡åŒæ¸…æ™¨åœºæ™¯ï¼Œé˜³å…‰æ´’åœ¨é’ç –ç°ç“¦ä¸Š",
            "èƒ¡åŒé‡Œçš„å­©å­ä»¬åœ¨ç©è€ï¼Œå……æ»¡ç”Ÿæ´»æ°”æ¯",
            "ä¼ ç»ŸåŒ—äº¬å››åˆé™¢ï¼Œçº¢é—¨ç»¿ç“¦",
        ],
    }


@pytest.fixture
def sample_image_prompt() -> str:
    """æä¾›ç¤ºä¾‹å›¾ç‰‡æç¤ºè¯"""
    return "è€åŒ—äº¬èƒ¡åŒæ¸…æ™¨åœºæ™¯ï¼Œé˜³å…‰æ´’åœ¨é’ç –ç°ç“¦ä¸Šï¼Œå¤å¤æ‘„å½±é£æ ¼"


# ============================================================================
# Mock å›ºä»¶
# ============================================================================


@pytest.fixture
def mock_openai_response():
    """æ¨¡æ‹Ÿ OpenAI API å“åº”"""

    class MockResponse:
        def __init__(self):
            self.choices = [
                type(
                    "obj",
                    (object,),
                    {
                        "message": type(
                            "obj", (object,), {"content": '{"titles": ["æµ‹è¯•æ ‡é¢˜"], "content": "æµ‹è¯•å†…å®¹"}'}
                        )()
                    },
                )()
            ]

    return MockResponse()


@pytest.fixture
def mock_image_api_response():
    """æ¨¡æ‹Ÿå›¾ç‰‡ç”Ÿæˆ API å“åº”"""
    return {
        "output": {
            "task_id": "test-task-id-123",
            "task_status": "SUCCEEDED",
            "results": [{"url": "https://example.com/image.jpg"}],
        }
    }


# ============================================================================
# è·³è¿‡æ¡ä»¶
# ============================================================================


def pytest_configure(config):
    """é…ç½® pytest"""
    config.addinivalue_line("markers", "unit: å•å…ƒæµ‹è¯•")
    config.addinivalue_line("markers", "integration: é›†æˆæµ‹è¯•")
    config.addinivalue_line("markers", "e2e: ç«¯åˆ°ç«¯æµ‹è¯•")
    config.addinivalue_line("markers", "slow: æ…¢é€Ÿæµ‹è¯•ï¼ˆè¶…è¿‡1ç§’ï¼‰")
    config.addinivalue_line("markers", "api: éœ€è¦APIå¯†é’¥çš„æµ‹è¯•")
    config.addinivalue_line("markers", "network: éœ€è¦ç½‘ç»œè¿æ¥çš„æµ‹è¯•")


def pytest_collection_modifyitems(config, items):
    """ä¿®æ”¹æµ‹è¯•æ”¶é›†"""
    # å¦‚æœæ²¡æœ‰ API Keyï¼Œè·³è¿‡éœ€è¦ API çš„æµ‹è¯•
    if not os.getenv("OPENAI_API_KEY"):
        skip_api = pytest.mark.skip(reason="éœ€è¦ OPENAI_API_KEY ç¯å¢ƒå˜é‡")
        for item in items:
            if "api" in item.keywords:
                item.add_marker(skip_api)

    # å¦‚æœæŒ‡å®šäº†å¿«é€Ÿæ¨¡å¼ï¼Œè·³è¿‡æ…¢é€Ÿæµ‹è¯•
    if config.getoption("-m") == "not slow":
        skip_slow = pytest.mark.skip(reason="è·³è¿‡æ…¢é€Ÿæµ‹è¯•")
        for item in items:
            if "slow" in item.keywords:
                item.add_marker(skip_slow)


# ============================================================================
# æµ‹è¯•æŠ¥å‘Šé’©å­
# ============================================================================


def pytest_report_header(config):
    """æ·»åŠ æµ‹è¯•æŠ¥å‘Šå¤´éƒ¨ä¿¡æ¯"""
    return ["RedBookContentGen æµ‹è¯•å¥—ä»¶", f"Python ç‰ˆæœ¬: {sys.version}", f"é¡¹ç›®æ ¹ç›®å½•: {project_root}"]


@pytest.hookimpl(tryfirst=True, hookwrapper=True)
def pytest_runtest_makereport(item, call):
    """ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š"""
    outcome = yield
    rep = outcome.get_result()

    # ä¸ºå¤±è´¥çš„æµ‹è¯•æ·»åŠ é¢å¤–ä¿¡æ¯
    if rep.when == "call" and rep.failed:
        # å¯ä»¥åœ¨è¿™é‡Œæ·»åŠ æˆªå›¾ã€æ—¥å¿—ç­‰
        pass
