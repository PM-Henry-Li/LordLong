#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æµ‹è¯•å†…å®¹ç”ŸæˆåŠŸèƒ½

ä»»åŠ¡ 9.1.1: æµ‹è¯•å†…å®¹ç”ŸæˆåŠŸèƒ½
- æµ‹è¯•æ­£å¸¸ç”Ÿæˆæµç¨‹
- æµ‹è¯•ä¸åŒè¾“å…¥é•¿åº¦
- æµ‹è¯•ä¸åŒé£æ ¼å‚æ•°

ç›®æ ‡ï¼šæµ‹è¯•è¦†ç›–ç‡ > 70%

æ³¨æ„ï¼šæœ¬æµ‹è¯•ä¸“æ³¨äºæµ‹è¯•å…¬å…±æ¥å£å’Œå¯è§‚å¯Ÿçš„è¡Œä¸ºï¼Œ
ä¸æµ‹è¯•å†…éƒ¨åµŒå¥—å‡½æ•°ï¼ˆå¦‚ _check_cache, _initialize_openai_client ç­‰ï¼‰
"""

import pytest
import json
import tempfile
from pathlib import Path
from unittest.mock import Mock, patch, MagicMock
from typing import Dict, Any

from src.content_generator import RedBookContentGenerator
from src.core.config_manager import ConfigManager


# ============================================================================
# æµ‹è¯•å›ºä»¶
# ============================================================================


@pytest.fixture
def mock_openai_client():
    """æ¨¡æ‹Ÿ OpenAI å®¢æˆ·ç«¯"""
    mock_client = Mock()
    mock_response = Mock()
    mock_response.choices = [
        Mock(
            message=Mock(
                content=json.dumps(
                    {
                        "titles": [
                            "èƒ¡åŒé‡Œçš„è€åŒ—äº¬è®°å¿† ğŸ®",
                            "é‚£äº›å¹´ï¼Œæˆ‘ä»¬ä¸€èµ·èµ°è¿‡çš„èƒ¡åŒ",
                            "è€åŒ—äº¬èƒ¡åŒï¼šæ—¶å…‰é‡Œçš„æ¸©æš–",
                            "èƒ¡åŒæ·±å¤„çš„ç«¥å¹´æ—¶å…‰",
                            "å¯»æ‰¾è€åŒ—äº¬çš„å‘³é“",
                        ],
                        "content": "è®°å¾—å°æ—¶å€™çš„è€åŒ—äº¬èƒ¡åŒå—ï¼Ÿæ¸…æ™¨çš„è±†è…å†å–å£°ä»å··å­æ·±å¤„ä¼ æ¥ï¼Œæ‚ é•¿è€Œäº²åˆ‡ã€‚é‚»é‡Œä¹‹é—´ä¸²é—¨èŠå¤©ï¼Œå­©å­ä»¬åœ¨èƒ¡åŒé‡Œè¿½é€å¬‰æˆã€‚é‚£æ—¶å€™çš„ç”Ÿæ´»è™½ç„¶ç®€å•ï¼Œä½†å……æ»¡äº†äººæƒ…å‘³ã€‚",
                        "tags": "#è€åŒ—äº¬ #èƒ¡åŒæ–‡åŒ– #ç«¥å¹´å›å¿† #åŒ—äº¬ç”Ÿæ´»",
                        "image_prompts": [
                            {
                                "scene": "èƒ¡åŒæ¸…æ™¨",
                                "prompt": "è€åŒ—äº¬èƒ¡åŒæ¸…æ™¨åœºæ™¯ï¼Œé˜³å…‰æ´’åœ¨é’ç –ç°ç“¦ä¸Šï¼Œå¤å¤æ‘„å½±é£æ ¼ï¼Œ90å¹´ä»£çºªå®æ‘„å½±",
                            },
                            {
                                "scene": "å­©å­ä»¬ç©è€",
                                "prompt": "èƒ¡åŒé‡Œçš„å­©å­ä»¬åœ¨ç©è€ï¼Œå……æ»¡ç”Ÿæ´»æ°”æ¯ï¼Œèƒ¶ç‰‡è´¨æ„Ÿ",
                            },
                            {
                                "scene": "å››åˆé™¢",
                                "prompt": "ä¼ ç»ŸåŒ—äº¬å››åˆé™¢ï¼Œçº¢é—¨ç»¿ç“¦ï¼Œå¤æœ´å…¸é›…",
                            },
                            {
                                "scene": "é‚»é‡ŒèŠå¤©",
                                "prompt": "é‚»å±…ä»¬åœ¨èƒ¡åŒå£èŠå¤©ï¼Œæ¸©é¦¨å’Œè°çš„åœºæ™¯",
                            },
                        ],
                        "cover": {
                            "scene": "èƒ¡åŒå…¨æ™¯",
                            "title": "è€åŒ—äº¬èƒ¡åŒè®°å¿†",
                            "prompt": "è€åŒ—äº¬èƒ¡åŒå…¨æ™¯ï¼Œé’ç –ç°ç“¦ï¼Œå……æ»¡å†å²æ„Ÿ",
                        },
                    },
                    ensure_ascii=False,
                )
            )
        )
    ]
    mock_client.chat.completions.create.return_value = mock_response
    return mock_client


@pytest.fixture
def test_config(temp_dir):
    """åˆ›å»ºæµ‹è¯•é…ç½®"""
    config_data = {
        "input_file": str(temp_dir / "input.txt"),
        "output_excel": str(temp_dir / "output" / "test.xlsx"),
        "output_image_dir": str(temp_dir / "output" / "images"),
        "openai_api_key": "test-api-key-12345",
        "openai_model": "qwen-plus",
        "openai_base_url": "https://dashscope.aliyuncs.com/compatible-mode/v1",
        "cache": {"enabled": False},  # ç¦ç”¨ç¼“å­˜ä»¥ä¾¿æµ‹è¯•
        "rate_limit": {"openai": {"enable_rate_limit": False}},  # ç¦ç”¨é€Ÿç‡é™åˆ¶
    }

    config_file = temp_dir / "config.json"
    with open(config_file, "w", encoding="utf-8") as f:
        json.dump(config_data, f, ensure_ascii=False, indent=2)

    return config_file


@pytest.fixture
def generator(test_config):
    """åˆ›å»ºå†…å®¹ç”Ÿæˆå™¨å®ä¾‹"""
    config_manager = ConfigManager(str(test_config))
    return RedBookContentGenerator(config_manager=config_manager)


# ============================================================================
# æµ‹è¯• 1: æ­£å¸¸ç”Ÿæˆæµç¨‹
# ============================================================================


@pytest.mark.unit
def test_normal_generation_flow(generator, mock_openai_client):
    """æµ‹è¯•æ­£å¸¸çš„å†…å®¹ç”Ÿæˆæµç¨‹"""
    input_text = """
    è®°å¾—å°æ—¶å€™ï¼Œè€åŒ—äº¬çš„èƒ¡åŒé‡Œæ€»æ˜¯å……æ»¡äº†ç”Ÿæ´»çš„æ°”æ¯ã€‚
    æ¸…æ™¨ï¼Œå–è±†è…çš„å†å–å£°ä»å··å­æ·±å¤„ä¼ æ¥ï¼Œæ‚ é•¿è€Œäº²åˆ‡ã€‚
    é‚»é‡Œä¹‹é—´ä¸²é—¨èŠå¤©ï¼Œå­©å­ä»¬åœ¨èƒ¡åŒé‡Œè¿½é€å¬‰æˆã€‚
    é‚£æ—¶å€™çš„ç”Ÿæ´»è™½ç„¶ç®€å•ï¼Œä½†å……æ»¡äº†äººæƒ…å‘³ã€‚
    """

    with patch("openai.OpenAI", return_value=mock_openai_client):
        result = generator.generate_content(input_text)

        # éªŒè¯è¿”å›ç»“æœçš„ç»“æ„
        assert isinstance(result, dict)
        assert "titles" in result
        assert "content" in result
        assert "tags" in result
        assert "image_prompts" in result
        assert "cover" in result

        # éªŒè¯æ ‡é¢˜
        assert isinstance(result["titles"], list)
        assert len(result["titles"]) == 5
        assert all(isinstance(title, str) for title in result["titles"])

        # éªŒè¯æ­£æ–‡
        assert isinstance(result["content"], str)
        assert len(result["content"]) > 0

        # éªŒè¯æ ‡ç­¾
        assert isinstance(result["tags"], str)
        assert "#" in result["tags"]

        # éªŒè¯å›¾ç‰‡æç¤ºè¯
        assert isinstance(result["image_prompts"], list)
        assert len(result["image_prompts"]) >= 4
        for prompt in result["image_prompts"]:
            assert "scene" in prompt
            assert "prompt" in prompt

        # éªŒè¯å°é¢
        assert isinstance(result["cover"], dict)
        assert "scene" in result["cover"]
        assert "title" in result["cover"]
        assert "prompt" in result["cover"]


# ============================================================================
# æµ‹è¯• 2: ä¸åŒè¾“å…¥é•¿åº¦
# ============================================================================


@pytest.mark.unit
@pytest.mark.parametrize(
    "input_length,input_text",
    [
        # çŸ­æ–‡æœ¬ï¼ˆçº¦50å­—ï¼‰
        (
            "short",
            "è€åŒ—äº¬çš„èƒ¡åŒï¼Œé’ç –ç°ç“¦ï¼Œå……æ»¡äº†å†å²çš„ç—•è¿¹ã€‚é‚£é‡Œæœ‰æˆ‘ç«¥å¹´çš„è®°å¿†ï¼Œæœ‰é‚»é‡Œçš„æ¸©æƒ…ã€‚",
        ),
        # ä¸­ç­‰æ–‡æœ¬ï¼ˆçº¦150å­—ï¼‰
        (
            "medium",
            """
            è®°å¾—å°æ—¶å€™ï¼Œè€åŒ—äº¬çš„èƒ¡åŒé‡Œæ€»æ˜¯å……æ»¡äº†ç”Ÿæ´»çš„æ°”æ¯ã€‚
            æ¸…æ™¨ï¼Œå–è±†è…çš„å†å–å£°ä»å··å­æ·±å¤„ä¼ æ¥ï¼Œæ‚ é•¿è€Œäº²åˆ‡ã€‚
            é‚»é‡Œä¹‹é—´ä¸²é—¨èŠå¤©ï¼Œå­©å­ä»¬åœ¨èƒ¡åŒé‡Œè¿½é€å¬‰æˆã€‚
            é‚£æ—¶å€™çš„ç”Ÿæ´»è™½ç„¶ç®€å•ï¼Œä½†å……æ»¡äº†äººæƒ…å‘³ã€‚
            å¤å¤©çš„å‚æ™šï¼Œå¤§å®¶éƒ½æ¬ç€å°æ¿å‡³ååœ¨èƒ¡åŒå£ä¹˜å‡‰ï¼Œ
            èŠç€å®¶é•¿é‡ŒçŸ­ï¼Œå­©å­ä»¬åˆ™åœ¨ä¸€æ—ç©ç€å¼¹ç ã€è·³çš®ç­‹ã€‚
            """,
        ),
        # é•¿æ–‡æœ¬ï¼ˆçº¦300å­—ï¼‰
        (
            "long",
            """
            è€åŒ—äº¬çš„èƒ¡åŒï¼Œæ˜¯è¿™åº§åŸå¸‚æœ€å…·ç‰¹è‰²çš„æ–‡åŒ–ç¬¦å·ä¹‹ä¸€ã€‚
            é‚£äº›çºµæ¨ªäº¤é”™çš„å°å··ï¼Œæ‰¿è½½ç€å‡ ä»£äººçš„è®°å¿†å’Œæƒ…æ„Ÿã€‚
            
            è®°å¾—å°æ—¶å€™ï¼Œèƒ¡åŒé‡Œçš„ç”Ÿæ´»èŠ‚å¥å¾ˆæ…¢ï¼Œä½†å´å……æ»¡äº†çƒŸç«æ°”ã€‚
            æ¸…æ™¨ï¼Œå–è±†è…çš„å†å–å£°ä»å··å­æ·±å¤„ä¼ æ¥ï¼Œæ‚ é•¿è€Œäº²åˆ‡ã€‚
            é‚»é‡Œä¹‹é—´ä¸²é—¨èŠå¤©ï¼Œå­©å­ä»¬åœ¨èƒ¡åŒé‡Œè¿½é€å¬‰æˆã€‚
            é‚£æ—¶å€™çš„ç”Ÿæ´»è™½ç„¶ç®€å•ï¼Œä½†å……æ»¡äº†äººæƒ…å‘³ã€‚
            
            å¤å¤©çš„å‚æ™šï¼Œå¤§å®¶éƒ½æ¬ç€å°æ¿å‡³ååœ¨èƒ¡åŒå£ä¹˜å‡‰ï¼Œ
            èŠç€å®¶é•¿é‡ŒçŸ­ï¼Œå­©å­ä»¬åˆ™åœ¨ä¸€æ—ç©ç€å¼¹ç ã€è·³çš®ç­‹ã€‚
            è€äººä»¬æ‘‡ç€è’²æ‰‡ï¼Œè®²è¿°ç€è€åŒ—äº¬çš„æ•…äº‹ã€‚
            
            å¦‚ä»Šï¼Œè®¸å¤šèƒ¡åŒå·²ç»æ¶ˆå¤±åœ¨åŸå¸‚åŒ–çš„è¿›ç¨‹ä¸­ï¼Œ
            ä½†é‚£äº›è®°å¿†å´æ°¸è¿œç•™åœ¨äº†æˆ‘ä»¬å¿ƒä¸­ã€‚
            æ¯å½“æƒ³èµ·é‚£äº›æ—¥å­ï¼Œå¿ƒä¸­æ€»ä¼šæ¶Œèµ·ä¸€è‚¡æ¸©æš–ã€‚
            """,
        ),
    ],
)
def test_different_input_lengths(generator, mock_openai_client, input_length, input_text):
    """æµ‹è¯•ä¸åŒé•¿åº¦çš„è¾“å…¥æ–‡æœ¬"""
    with patch("openai.OpenAI", return_value=mock_openai_client):
        result = generator.generate_content(input_text)

        # éªŒè¯åŸºæœ¬ç»“æ„
        assert isinstance(result, dict)
        assert "titles" in result
        assert "content" in result
        assert "image_prompts" in result

        # éªŒè¯ç”Ÿæˆçš„å†…å®¹ä¸ä¸ºç©º
        assert len(result["titles"]) > 0
        assert len(result["content"]) > 0
        assert len(result["image_prompts"]) > 0

        # éªŒè¯ API è¢«è°ƒç”¨
        assert mock_openai_client.chat.completions.create.called


# ============================================================================
# æµ‹è¯• 3: ä¸åŒé£æ ¼å‚æ•°ï¼ˆé€šè¿‡æ¸©åº¦å‚æ•°æ¨¡æ‹Ÿï¼‰
# ============================================================================


@pytest.mark.unit
@pytest.mark.parametrize(
    "temperature,expected_style",
    [
        (0.3, "ä¿å®ˆé£æ ¼"),  # ä½æ¸©åº¦ï¼Œæ›´ä¿å®ˆçš„è¾“å‡º
        (0.8, "å¹³è¡¡é£æ ¼"),  # ä¸­ç­‰æ¸©åº¦ï¼Œå¹³è¡¡çš„è¾“å‡º
        (1.2, "åˆ›æ„é£æ ¼"),  # é«˜æ¸©åº¦ï¼Œæ›´æœ‰åˆ›æ„çš„è¾“å‡º
    ],
)
def test_different_style_parameters(generator, mock_openai_client, temperature, expected_style):
    """æµ‹è¯•ä¸åŒçš„é£æ ¼å‚æ•°ï¼ˆé€šè¿‡æ¸©åº¦å‚æ•°ï¼‰"""
    input_text = "è€åŒ—äº¬çš„èƒ¡åŒæ–‡åŒ–ï¼Œå……æ»¡äº†å†å²çš„éŸµå‘³ã€‚"

    with patch("openai.OpenAI", return_value=mock_openai_client):
        # ä¿®æ”¹é…ç½®ä¸­çš„æ¸©åº¦å‚æ•°
        with patch.object(
            generator.api_handler, "call_openai", wraps=generator.api_handler.call_openai
        ) as mock_call:
            result = generator.generate_content(input_text)

            # éªŒè¯ç»“æœ
            assert isinstance(result, dict)
            assert "titles" in result
            assert "content" in result

            # éªŒè¯ API è¢«è°ƒç”¨
            assert mock_call.called


# ============================================================================
# æµ‹è¯• 4: å†…å®¹å®‰å…¨æ£€æŸ¥
# ============================================================================


@pytest.mark.unit
def test_content_safety_check(generator):
    """æµ‹è¯•å†…å®¹å®‰å…¨æ£€æŸ¥åŠŸèƒ½"""
    # æµ‹è¯•å®‰å…¨å†…å®¹
    safe_text = "è€åŒ—äº¬çš„èƒ¡åŒæ–‡åŒ–ï¼Œå……æ»¡äº†å†å²çš„éŸµå‘³ã€‚"
    is_safe, modified = generator.check_content_safety(safe_text)
    assert is_safe is True
    assert modified == safe_text

    # æµ‹è¯•åŒ…å«æ•æ„Ÿè¯çš„å†…å®¹ï¼ˆåªæµ‹è¯•æ˜æ˜¾çš„æ•æ„Ÿè¯ï¼‰
    unsafe_text = "è¿™æ˜¯ä¸€æ®µåŒ…å«è¡€è…¥çš„å†…å®¹ã€‚"
    is_safe, modified = generator.check_content_safety(unsafe_text)
    assert is_safe is False
    # éªŒè¯æ•æ„Ÿè¯è¢«ç§»é™¤
    assert "è¡€è…¥" not in modified
    # éªŒè¯å…¶ä»–å†…å®¹ä¿ç•™
    assert "è¿™æ˜¯ä¸€æ®µåŒ…å«" in modified
    assert "çš„å†…å®¹" in modified


# ============================================================================
# æµ‹è¯• 5: ç¼“å­˜é”®ç”Ÿæˆ
# ============================================================================


@pytest.mark.unit
def test_cache_key_generation(generator):
    """æµ‹è¯•ç¼“å­˜é”®ç”ŸæˆåŠŸèƒ½"""
    input_text1 = "è€åŒ—äº¬çš„èƒ¡åŒæ–‡åŒ–"
    input_text2 = "è€åŒ—äº¬çš„èƒ¡åŒæ–‡åŒ–"
    input_text3 = "ä¸åŒçš„è¾“å…¥å†…å®¹"

    key1 = generator._generate_cache_key(input_text1)
    key2 = generator._generate_cache_key(input_text2)
    key3 = generator._generate_cache_key(input_text3)

    # ç›¸åŒè¾“å…¥åº”è¯¥ç”Ÿæˆç›¸åŒçš„ç¼“å­˜é”®
    assert key1 == key2

    # ä¸åŒè¾“å…¥åº”è¯¥ç”Ÿæˆä¸åŒçš„ç¼“å­˜é”®
    assert key1 != key3

    # ç¼“å­˜é”®åº”è¯¥åŒ…å«å‰ç¼€
    assert key1.startswith("content_gen:")


# ============================================================================
# æµ‹è¯• 6: æç¤ºè¯æ„å»º
# ============================================================================


@pytest.mark.unit
def test_prompt_building(generator):
    """æµ‹è¯•æç¤ºè¯æ„å»ºåŠŸèƒ½"""
    input_text = "è€åŒ—äº¬çš„èƒ¡åŒæ–‡åŒ–"
    prompt = generator._build_generation_prompt(input_text)

    # éªŒè¯æç¤ºè¯åŒ…å«å¿…è¦çš„å…ƒç´ 
    assert "è€åŒ—äº¬æ–‡åŒ–" in prompt
    assert "å°çº¢ä¹¦" in prompt
    assert "AI ç»˜ç”»" in prompt or "AIç»˜ç”»" in prompt
    # æ³¨æ„ï¼šæç¤ºè¯æ¨¡æ¿ä½¿ç”¨ {raw_content} å ä½ç¬¦ï¼Œä¸ä¼šç›´æ¥åŒ…å«è¾“å…¥æ–‡æœ¬
    assert "{raw_content}" in prompt

    # éªŒè¯æç¤ºè¯åŒ…å«è¾“å‡ºæ ¼å¼è¯´æ˜
    assert "titles" in prompt
    assert "content" in prompt
    assert "image_prompts" in prompt


# ============================================================================
# æµ‹è¯• 7: å•æ¡å†…å®¹ç”Ÿæˆï¼ˆWeb API ä½¿ç”¨ï¼‰
# ============================================================================


@pytest.mark.unit
def test_generate_single_content(generator, mock_openai_client):
    """æµ‹è¯•å•æ¡å†…å®¹ç”ŸæˆåŠŸèƒ½ï¼ˆç”¨äº Web APIï¼‰"""
    input_text = "è€åŒ—äº¬çš„èƒ¡åŒæ–‡åŒ–"

    with patch("openai.OpenAI", return_value=mock_openai_client):
        result = generator.generate_single_content(input_text)

        # éªŒè¯è¿”å›ç»“æœçš„ç»“æ„
        assert isinstance(result, dict)
        assert "title" in result
        assert "content" in result
        assert "tags" in result
        assert "image_prompt" in result
        assert "raw_data" in result

        # éªŒè¯æ ‡é¢˜æ˜¯å­—ç¬¦ä¸²
        assert isinstance(result["title"], str)

        # éªŒè¯æ ‡ç­¾æ˜¯åˆ—è¡¨
        assert isinstance(result["tags"], list)

        # éªŒè¯åŸå§‹æ•°æ®è¢«ä¿ç•™
        assert isinstance(result["raw_data"], dict)


# ============================================================================
# æµ‹è¯• 8: é”™è¯¯å¤„ç†
# ============================================================================


@pytest.mark.unit
def test_error_handling_missing_api_key(test_config):
    """æµ‹è¯•ç¼ºå°‘ API Key çš„é”™è¯¯å¤„ç†"""
    # åˆ›å»ºæ²¡æœ‰ API Key çš„é…ç½®
    config_data = {
        "input_file": "input/test.txt",
        "output_excel": "output/test.xlsx",
        "output_image_dir": "output/images",
        # æ•…æ„ä¸è®¾ç½® openai_api_key
    }

    with tempfile.TemporaryDirectory() as temp_dir:
        config_file = Path(temp_dir) / "config.json"
        with open(config_file, "w", encoding="utf-8") as f:
            json.dump(config_data, f)

        config_manager = ConfigManager(str(config_file))
        generator = RedBookContentGenerator(config_manager=config_manager)

        # å°è¯•ç”Ÿæˆå†…å®¹åº”è¯¥æŠ›å‡ºé”™è¯¯
        with pytest.raises(ValueError, match="æœªæ‰¾åˆ° API Key"):
            generator.generate_content("æµ‹è¯•å†…å®¹")


@pytest.mark.unit
def test_error_handling_empty_input(generator):
    """æµ‹è¯•ç©ºè¾“å…¥çš„é”™è¯¯å¤„ç†"""
    # ç©ºå­—ç¬¦ä¸²åº”è¯¥èƒ½å¤Ÿå¤„ç†ï¼ˆè™½ç„¶å¯èƒ½è¿”å›ç©ºç»“æœï¼‰
    with patch("openai.OpenAI") as mock_client:
        mock_response = Mock()
        mock_response.choices = [
            Mock(
                message=Mock(
                    content=json.dumps(
                        {
                            "titles": ["é»˜è®¤æ ‡é¢˜"],
                            "content": "é»˜è®¤å†…å®¹",
                            "tags": "#é»˜è®¤",
                            "image_prompts": [],
                            "cover": {},
                        }
                    )
                )
            )
        ]
        mock_client.return_value.chat.completions.create.return_value = mock_response

        result = generator.generate_content("")
        assert isinstance(result, dict)


# ============================================================================
# æµ‹è¯• 9: é…ç½®å’Œåˆå§‹åŒ–
# ============================================================================


@pytest.mark.unit
def test_generator_initialization(test_config):
    """æµ‹è¯•ç”Ÿæˆå™¨åˆå§‹åŒ–"""
    config_manager = ConfigManager(str(test_config))
    generator = RedBookContentGenerator(config_manager=config_manager)

    # éªŒè¯ç”Ÿæˆå™¨æ­£ç¡®åˆå§‹åŒ–
    assert generator.config_manager is not None
    assert generator.logger is not None
    assert hasattr(generator, "image_dir")
    assert hasattr(generator, "_cache_enabled")
    assert hasattr(generator, "_rate_limit_enabled")


@pytest.mark.unit
def test_generator_with_cache_disabled(test_config):
    """æµ‹è¯•ç¦ç”¨ç¼“å­˜çš„ç”Ÿæˆå™¨"""
    config_manager = ConfigManager(str(test_config))
    generator = RedBookContentGenerator(config_manager=config_manager)

    # éªŒè¯ç¼“å­˜è¢«ç¦ç”¨
    assert generator._cache_enabled is False
    assert generator.cache is None


@pytest.mark.unit
def test_generator_with_rate_limit_disabled(test_config):
    """æµ‹è¯•ç¦ç”¨é€Ÿç‡é™åˆ¶çš„ç”Ÿæˆå™¨"""
    config_manager = ConfigManager(str(test_config))
    generator = RedBookContentGenerator(config_manager=config_manager)

    # éªŒè¯é€Ÿç‡é™åˆ¶è¢«ç¦ç”¨
    assert generator._rate_limit_enabled is False
    assert generator.rpm_limiter is None
    assert generator.tpm_limiter is None


if __name__ == "__main__":
    pytest.main([__file__, "-v", "--cov=src.content_generator", "--cov-report=term-missing"])
